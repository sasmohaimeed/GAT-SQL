{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Hello,\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "### **Before we began please upload the following files (They are similar to the files that are attached to the email) :**\n",
        "\n",
        "- dev.json\n",
        "- tables.json\n",
        "- database.zip ( this zip file contain a database folder)\n",
        "- predict.txt ( this file contain the prediction queries from Star or Rasat model )"
      ],
      "metadata": {
        "id": "TFknavvD10HX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **In Cell 1 please do the following**\n",
        "\n",
        "Fill in the openai.organization = \"org-XXX\" **( write your own organization key instead of org-XXX)**\n",
        "\n",
        "Fill in the openai.api_key = 'sk-xxxxx' **( write your own Open AI key instead of sk-xxxxx )**\n",
        "\n",
        "Fill in the 'Authorization': f'Bearer sk-xxxxx' **( write your own Open AI key instead of sk-xxxxx )**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "hPmwK3p88jVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **After you done from writing the keys, please run Cell 1, 2, 3, 4, 5, 6 in the same order**\n",
        "\n",
        "Cell 6: is the one that going to call GPT-3.5-turbo and only going to take approximatly 20 min for 1000 questions\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "iI3vdrY187MJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Once Cell 6 ends run Cell 7 and you will get the new_predict.txt file**"
      ],
      "metadata": {
        "id": "6Pj2dUGN9q8b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cell 1**"
      ],
      "metadata": {
        "id": "f_d0ubD576WM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9PBJ_zwcW_q"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import sqlite3\n",
        "import os\n",
        "import requests\n",
        "import re\n",
        "!pip3 install openai==0.27.0\n",
        "import os\n",
        "import openai\n",
        "import time\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "!pip install sentence_transformers\n",
        "\n",
        "openai.organization = \"org-XXXXXXXXXXX\"\n",
        "openai.api_key = 'sk-XXXXXXXXXXX'\n",
        "\n",
        "headers = {\n",
        "    'Content-Type': 'application/json',\n",
        "    'Authorization': f'Bearer sk-XXXXXXXXXXX'\n",
        "}\n",
        "\n",
        "openai.Model.list()\n",
        "\n",
        "with open('/content/dev.json', encoding='utf-8') as o:\n",
        "        dev = json.load(o)\n",
        "\n",
        "with open('/content/tables.json', encoding='utf-8') as o:\n",
        "        tables = json.load(o)\n",
        "\n",
        "!unzip /content/database.zip -d /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cell 2**"
      ],
      "metadata": {
        "id": "4HiWR__R8AI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_DB_values(db_id):\n",
        "  path = '/content/database/' + db_id + '/' + db_id + '.sqlite'\n",
        "  sqlite_db_path = path\n",
        "  conn = connect_sqlite(sqlite_db_path)\n",
        "  first_eight_rows_data_with_columns = fetch_first_eight_rows_with_column_names(conn)\n",
        "  return first_eight_rows_data_with_columns\n",
        "\n",
        "\n",
        "# Define the function to connect to the SQLite database file\n",
        "def connect_sqlite(db_path):\n",
        "    connection = sqlite3.connect(db_path)\n",
        "    return connection\n",
        "\n",
        "# Define the function to generate SQL for creating tables\n",
        "def generate_create_table_sql(connection):\n",
        "    cursor = connection.cursor()\n",
        "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "    tables = cursor.fetchall()\n",
        "\n",
        "    create_table_sql = []\n",
        "\n",
        "    for table_name in tables:\n",
        "        cursor.execute(f\"PRAGMA table_info({table_name[0]})\")\n",
        "        columns = cursor.fetchall()\n",
        "\n",
        "        column_definitions = []\n",
        "        for column in columns:\n",
        "            col_def = f\"{column[1]} {column[2]}\"\n",
        "            if column[3]:  # Checking for NOT NULL\n",
        "                col_def += \" NOT NULL\"\n",
        "            if column[5]:  # Checking for primary key\n",
        "                col_def += \" PRIMARY KEY\"\n",
        "            column_definitions.append(col_def)\n",
        "\n",
        "        create_stmt = f\"CREATE TABLE {table_name[0]} ({', '.join(column_definitions)});\"\n",
        "        create_table_sql.append(create_stmt)\n",
        "\n",
        "    return create_table_sql\n",
        "\n",
        "# Define the function to fetch the first two rows and column names from each table\n",
        "def fetch_first_eight_rows_with_column_names(connection):\n",
        "    cursor = connection.cursor()\n",
        "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "    tables = cursor.fetchall()\n",
        "\n",
        "    table_data_with_columns = {}\n",
        "\n",
        "    for table_name in tables:\n",
        "        cursor.execute(f\"SELECT * FROM {table_name[0]} LIMIT 8;\")\n",
        "        data = cursor.fetchall()\n",
        "        cursor.execute(f\"PRAGMA table_info({table_name[0]})\")\n",
        "        columns = [col[1] for col in cursor.fetchall()]  # Extract column names\n",
        "        table_data_with_columns[table_name[0]] = {'columns': columns, 'rows': data}\n",
        "\n",
        "    return table_data_with_columns"
      ],
      "metadata": {
        "id": "6JjgflZUcrG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cell 3**"
      ],
      "metadata": {
        "id": "nph7EF2U8C8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## GET the model predictions from RASAT MODEL or STAR MODEL\n",
        "\n",
        "with open('/content/predict.txt', 'r') as file:\n",
        "    # Reading the content of the file\n",
        "    file_content = file.read()\n",
        "\n",
        "with open('/content/test.json', encoding='utf-8') as o:\n",
        "        dev = json.load(o)\n",
        "\n",
        "# Split the content by new lines into an array\n",
        "sql_queries_array_from_file = file_content.split('\\n')\n",
        "cleaned_list = [s for s in sql_queries_array_from_file if s.strip() != \"\"]\n",
        "\n",
        "ArrayModel_prediction = []\n",
        "i = 0\n",
        "for e in dev:\n",
        "  interaction_list = []\n",
        "  for s in e['interaction']:\n",
        "    tempdict = {}\n",
        "    tempdict['db_id'] = e['database_id']\n",
        "    tempdict['question'] = s['utterance']\n",
        "    tempdict['query'] = cleaned_list[i]\n",
        "    i = i + 1\n",
        "    interaction_list.append(tempdict)\n",
        "\n",
        "  ArrayModel_prediction.append(interaction_list)\n",
        "\n",
        "\n",
        "# Now we will save this array to a JSON file.\n",
        "json_file_path = 'Model_prediction.json'\n",
        "\n",
        "# Writing the array to a JSON file.\n",
        "with open(json_file_path, 'w') as json_file:\n",
        "    json.dump(ArrayModel_prediction, json_file, indent=4)"
      ],
      "metadata": {
        "id": "wu2HGzPCcwyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cell 4**"
      ],
      "metadata": {
        "id": "itebXAjW8JaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getModelPrediction(interactionCounter ,sampleInInteractionCounter):\n",
        "  with open(json_file_path, encoding='utf-8') as o:\n",
        "        dev = json.load(o)\n",
        "\n",
        "  prediction = dev[interactionCounter][sampleInInteractionCounter]\n",
        "\n",
        "  return prediction"
      ],
      "metadata": {
        "id": "VOK2-EohNXP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cell 5**"
      ],
      "metadata": {
        "id": "r0oUHJhd8KjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def OpenAI_Prompt(question, schema, FirstQuestion, previous_query , questionDB, with_later_prediction, interactionCounter ,sampleInInteractionCounter):\n",
        "\n",
        "    def schema_Extraction_for_OpenAI_prompt(schema):\n",
        "            schemaString =  \"\"\n",
        "            i = 0\n",
        "            for t in schema['table_names_original']:\n",
        "              schemaString =  schemaString + \"# Table \" + t + \", columns = [ \"\n",
        "              for c in schema['column_names_original']:\n",
        "                if c[0] == i:\n",
        "                  schemaString = schemaString + c[1] + \", \"\n",
        "\n",
        "              schemaString = schemaString[:-2] + \" ]\"\n",
        "              schemaString = schemaString + \" \\n\"\n",
        "              i = i + 1\n",
        "            schemaString = schemaString + \"# Primary_keys = [ \"\n",
        "            for pk in schema['primary_keys']:\n",
        "              column_counter = 0\n",
        "              for c in schema['column_names_original']:\n",
        "                if column_counter == pk:\n",
        "                  schemaString = schemaString + schema['table_names_original'][c[0]]+ '.' + c[1] + \", \"\n",
        "                column_counter = column_counter + 1\n",
        "            schemaString = schemaString[:-2] + \" ]\"\n",
        "            schemaString = schemaString + \" \\n\"\n",
        "            schemaString = schemaString + \"# Foreign_keys = [ \"\n",
        "            for fk in schema['foreign_keys']:\n",
        "              column_counter = 0\n",
        "              for c in schema['column_names_original']:\n",
        "                if column_counter == fk[0]:\n",
        "                  schemaString = schemaString + schema['table_names_original'][c[0]]+ '.' + c[1] + \" foreign key referenced to \"\n",
        "                  another_column_counter = 0\n",
        "                  for c in schema['column_names_original']:\n",
        "                    if another_column_counter == fk[1]:\n",
        "                      schemaString = schemaString + schema['table_names_original'][c[0]]+ '.' + c[1] + \" ], [\"\n",
        "                    another_column_counter = another_column_counter + 1\n",
        "                column_counter = column_counter + 1\n",
        "            schemaString = schemaString[:-3]\n",
        "            return schemaString\n",
        "\n",
        "    # Start creating the prompt\n",
        "    # Construct the schema\n",
        "    Intro = \"### Complete sqlite SQL query only and with no explanation \" + \"\\n\" + \"### SQLite SQL tables , with their properties :\"\n",
        "    Created_schema = schema_Extraction_for_OpenAI_prompt(schema)\n",
        "\n",
        "    # Control the response style\n",
        "    #instruction = \"Answer the follwoing question: \"\n",
        "    Correcting_message = \"# Please provide a direct SQL query with no additional text or explanations to correct it if necessary\"\n",
        "    Response_style = \"# The response must be a complete SQL query in code snippet starting with SELECT and ending with a semicolon.\"\n",
        "    Database_sentance = \"# These are examples of the first eight rows of the database scehma\"\n",
        "    database_values = str(get_DB_values(schema['db_id']))\n",
        "    Introduce_question = \"# For the following question:\"\n",
        "    Introduce_prediction = \"# Our model XSQL predict this query:\"\n",
        "\n",
        "    # Construct the Prompt\n",
        "    prediction = getModelPrediction(interactionCounter ,sampleInInteractionCounter)\n",
        "    prediction = prediction['query']\n",
        "\n",
        "\n",
        "    if FirstQuestion:\n",
        "      Prompt = Intro + \" \\n\" + Created_schema + \" \\n\" + Database_sentance + \" \\n\" + '#' + database_values + \" \\n\" + Introduce_question + \"### \" + question + \" \\n\" + Introduce_prediction + \" \\n\" + prediction + \" \\n\" + Correcting_message + \" \\n\" + Response_style\n",
        "    elif FirstQuestion == False and with_later_prediction:\n",
        "      T1 = \"# Based on the previous query: \"\n",
        "      Prompt = T1 + previous_query + \" \\n\" + \"### \" + question + \" \\n\" + Introduce_prediction + \" \\n\" + prediction + \" \\n\" + Correcting_message + \" \\n\" + Response_style\n",
        "    elif FirstQuestion == False and with_later_prediction == False:\n",
        "      T1 = \"# Based on the previous query: \"\n",
        "      T2 = \"# Please provide a direct SQL query with no additional text or explanations to answer this question:\"\n",
        "      Prompt = T1 + previous_query + \" \\n\" + T2 + \" \\n\" + \"### \" + question + \" \\n\" + Response_style\n",
        "\n",
        "\n",
        "    return Prompt"
      ],
      "metadata": {
        "id": "LPtSsx4CdMNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cell 6**"
      ],
      "metadata": {
        "id": "XmWUMg-h8MPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"gpt-3.5-turbo\"\n",
        "with_later_prediction = True\n",
        "\n",
        "def cleanResponse(result):\n",
        "  pattern = r\"SELECT .*?;\"\n",
        "  matches = re.findall(pattern, result, re.IGNORECASE | re.DOTALL)\n",
        "  for match in matches:\n",
        "      cleaned_match = match.strip().replace('\\n', ' ')\n",
        "  return cleaned_match\n",
        "\n",
        "GPT_final_result = []\n",
        "counter = 0\n",
        "\n",
        "interactionCounter = -1\n",
        "for e in dev:\n",
        "  interactionCounter = interactionCounter + 1\n",
        "  counter = counter + 1\n",
        "  # in case the model stop see the last number of the counter the model reach and write it instead of counter < 0\n",
        "  if counter < 0:\n",
        "    continue\n",
        "  print(counter)\n",
        "\n",
        "  interaction_result = []\n",
        "  # Finded the needed schema\n",
        "  for t in tables:\n",
        "    if e['database_id'] == t['db_id']:\n",
        "      schema = t\n",
        "      break\n",
        "\n",
        "  # Give the GPT4 or GPT3.5 a role name\n",
        "  messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that provides SQL queries based on user questions\"},\n",
        "      ]\n",
        "  # working first with the first question in the interaction\n",
        "  FirstQuestion = True\n",
        "  sampleInInteractionCounter = -1\n",
        "  for u in e['interaction']:\n",
        "      sampleInInteractionCounter = sampleInInteractionCounter + 1\n",
        "      if FirstQuestion == True:\n",
        "        previous_query = \"\"\n",
        "        Prompt = OpenAI_Prompt(u['utterance'], schema, FirstQuestion, previous_query, e['database_id'], with_later_prediction, interactionCounter ,sampleInInteractionCounter)\n",
        "        #print(Prompt)\n",
        "        #print(\"---\")\n",
        "        FirstQuestion = False\n",
        "      else:\n",
        "        previous_query = sql_query\n",
        "        Prompt = OpenAI_Prompt(u['utterance'], schema, FirstQuestion, previous_query, e['database_id'], with_later_prediction, interactionCounter ,sampleInInteractionCounter)\n",
        "        #print(Prompt)\n",
        "        #print(\"---\")\n",
        "\n",
        "      messages.append({\"role\": \"user\", \"content\": Prompt})\n",
        "      retry_count = 0\n",
        "      max_retries = 5\n",
        "      response = None\n",
        "      while retry_count < max_retries:\n",
        "          try:\n",
        "              response = openai.ChatCompletion.create(\n",
        "                  model=model,\n",
        "                  messages=messages,\n",
        "                  temperature= 0,\n",
        "                  request_timeout=32\n",
        "              )\n",
        "              break  # Break the retry loop if successful\n",
        "\n",
        "          except:\n",
        "              retry_count += 1\n",
        "              print(f\"Retry attempt {retry_count}/{max_retries}\")\n",
        "              time.sleep(5)  # Wait for a while before retrying\n",
        "\n",
        "      if response is None:\n",
        "          print(\"Max retries reached. Skipping this query.\")\n",
        "          continue  # Skip this query if max retries are reached\n",
        "\n",
        "      # Get the results of the content\n",
        "      result = response.choices[0].message['content']\n",
        "      try:\n",
        "      # clear the prompt to make sure that only include the sql query\n",
        "        sql_query = cleanResponse(result)\n",
        "      except:\n",
        "        sql_query = \"SELECT * FROM ERROR\"\n",
        "\n",
        "      #print(\"Predicted query \", sql_query)\n",
        "      #print(\"*****************************************\")\n",
        "      messages.append({\"role\": \"assistant\", \"content\": sql_query})\n",
        "      interaction_result.append(sql_query)\n",
        "      #print(interaction_result)\n",
        "\n",
        "  GPT_final_result.append(interaction_result)\n",
        "  #print(\"----------------- ----------------- ----------------- -----------------\")\n",
        "\n",
        "\n",
        "FileName = \"output.json\"\n",
        "\n",
        "with open(FileName, 'wt') as samozen:\n",
        "   json.dump(GPT_final_result, samozen, sort_keys=False, indent=4, separators=(',', ': '))"
      ],
      "metadata": {
        "id": "oIFLvs8mdcZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cell 7**"
      ],
      "metadata": {
        "id": "5dn7VQYd8QEL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run this cell to get the final new_pridct.txt file , that can be used to get the results"
      ],
      "metadata": {
        "id": "9YkvnEvF_iVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#generate the new_predict.txt file\n",
        "\n",
        "with open(FileName, encoding='utf-8') as o:\n",
        "        predict = json.load(o)\n",
        "\n",
        "\n",
        "with open(\"new_predict.txt\", \"w\") as file:\n",
        "    # Iterate through each element in the array\n",
        "    for element in predict:\n",
        "        for sample in element:\n",
        "        # Write each element as a new line in the text file\n",
        "          file.write(sample + \"\\n\")\n",
        "        file.write(\"\\n\")\n",
        "\n",
        "print(\"File has been created and data has been written!\")"
      ],
      "metadata": {
        "id": "rINbOREA-1gS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Thank you very much for your help**"
      ],
      "metadata": {
        "id": "reqct2TeAVo3"
      }
    }
  ]
}